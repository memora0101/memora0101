{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import trax\n",
    "import os\n",
    "import random as rnd\n",
    "import trax.fastmath.numpy as np\n",
    "from trax import layers as tl\n",
    "from trax import fastmath\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿chatid</th>\n",
       "      <th>user</th>\n",
       "      <th>chatorder</th>\n",
       "      <th>text</th>\n",
       "      <th>ANGRY</th>\n",
       "      <th>HAPPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello, is this apple product support?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bot</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes, it is. How may I help you?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert</td>\n",
       "      <td>3</td>\n",
       "      <td>I have a problem with one of the products that...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bot</td>\n",
       "      <td>4</td>\n",
       "      <td>I am sorry for that. Can you please tell which...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert</td>\n",
       "      <td>5</td>\n",
       "      <td>It is an iphone 10, it has been a week about n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Bot</td>\n",
       "      <td>6</td>\n",
       "      <td>I understand the situation and I am glad to as...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert</td>\n",
       "      <td>7</td>\n",
       "      <td>My order id is 54569723 and I would like to ha...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Bot</td>\n",
       "      <td>8</td>\n",
       "      <td>A replacement request has been created, please...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert</td>\n",
       "      <td>9</td>\n",
       "      <td>Thank you for you help, have a good day</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Bot</td>\n",
       "      <td>10</td>\n",
       "      <td>You're welcome, have a great day!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿chatid    user  chatorder  \\\n",
       "0          1  Robert          1   \n",
       "1          1     Bot          2   \n",
       "2          1  Robert          3   \n",
       "3          1     Bot          4   \n",
       "4          1  Robert          5   \n",
       "5          1     Bot          6   \n",
       "6          1  Robert          7   \n",
       "7          1     Bot          8   \n",
       "8          1  Robert          9   \n",
       "9          1     Bot         10   \n",
       "\n",
       "                                                text  ANGRY  HAPPY  \n",
       "0              Hello, is this apple product support?    0.0    0.3  \n",
       "1                    Yes, it is. How may I help you?    0.0    0.7  \n",
       "2  I have a problem with one of the products that...    0.7    0.0  \n",
       "3  I am sorry for that. Can you please tell which...    0.0    0.0  \n",
       "4  It is an iphone 10, it has been a week about n...    1.0    0.0  \n",
       "5  I understand the situation and I am glad to as...    0.0    2.0  \n",
       "6  My order id is 54569723 and I would like to ha...    0.3    0.0  \n",
       "7  A replacement request has been created, please...    0.0    0.7  \n",
       "8            Thank you for you help, have a good day    0.0    4.3  \n",
       "9                  You're welcome, have a great day!    0.0    4.7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"Benchmark.csv\",encoding='unicode_escape')\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "73\n",
      "80\n",
      "73\n",
      "(73,)\n"
     ]
    }
   ],
   "source": [
    "positive_text=df1.text[df1.HAPPY>0]\n",
    "negative_text=df1.text[df1.ANGRY>0]\n",
    "positive_labels=df1.HAPPY[df1.HAPPY>0]\n",
    "negative_labels=df1.ANGRY[df1.ANGRY>0]\n",
    "print(len(positive_text))\n",
    "print(len(negative_text))\n",
    "print(len(positive_labels))\n",
    "print(len(negative_labels))\n",
    "print(np.shape(negative_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pos = positive_text[64:].values.tolist()\n",
    "train_pos = positive_text[:64].values.tolist()\n",
    "val_neg = negative_text[58:].values.tolist()\n",
    "train_neg = negative_text[:58].values.tolist()\n",
    "val_lab_pos=positive_labels[64:].values.tolist()\n",
    "train_lab_pos=positive_labels[:64].values.tolist()\n",
    "val_lab_neg=negative_labels[58:].values.tolist()\n",
    "train_lab_neg=negative_labels[:58].values.tolist()\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "val_x = val_pos + val_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 2.  0.7 4.3 4.7 3.  0.3 3.  0.7 0.7 0.3 0.3 0.3 3.  3.3 1.  0.7\n",
      " 1.  0.3 0.7 0.3 1.  0.7 0.3 2.3 1.  4.3 3.3 3.  1.  0.7 0.3 1.  3.  0.3\n",
      " 4.3 4.7 2.  3.  0.3 0.7 0.7 0.3 0.3 0.3 1.7 0.3 0.7 0.7 0.3 3.3 4.7 4.7\n",
      " 1.3 0.3 0.7 3.  1.3 3.  1.3 1.  4.3 3.  0.7 1.  0.3 0.3 3.  0.3 4.7 5.\n",
      " 0.3 0.7 4.3 4.7 0.3 0.7 0.7 0.3 4.  5.  0.3 0.7 0.3 0.3 2.7 3.3 0.3 3.7\n",
      " 1.3 1.  0.7 0.3 2.7 1.7 1.7 3.7 0.3 0.7 0.3 0.3 0.3 0.3 0.7 0.7 1.  0.3\n",
      " 1.3 1.3 1.  1.3 1.7 1.7 0.3 3.7 1.  2.3 2.3 1.7 1.7 1.7]\n",
      "(122,)\n"
     ]
    }
   ],
   "source": [
    "train_y = np.array(train_lab_pos+train_lab_neg)\n",
    "print(train_y)\n",
    "print(np.shape(train_y))\n",
    "# Set the labels for the validation set (1 for positive, 0 for negative)\n",
    "val_y  = np.array(val_lab_pos+val_lab_neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       [hello, apple, product, support]\n",
      "1                                       [yes, may, help]\n",
      "2             [problem, one, products, purchased, store]\n",
      "3                  [sorry, please, tell, product, issue]\n",
      "4           [iphone, 10, week, phone, started, overheat]\n",
      "                             ...                        \n",
      "192                             [connect, someone, else]\n",
      "193                                          [apologize]\n",
      "194                                       [transferring]\n",
      "195                         [may, phone, number, please]\n",
      "196    [posting, conversation, online, unbelievable, ...\n",
      "Name: text, Length: 197, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def process_text(sent):\n",
    "    \"\"\"Process sent function.\n",
    "    Input:\n",
    "        sentence: a string containing a sentence\n",
    "    Output:\n",
    "        sent_clean: a list of words containing the processed sentence\n",
    "\n",
    "    \"\"\"\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    sent = re.sub(r'\\$\\w*', '', sent)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    sent = re.sub(r'^RT[\\s]+', '', sent)\n",
    "    # remove hyperlinks\n",
    "    sent = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sent)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    sent = re.sub(r'#', '', sent)\n",
    "    \n",
    "    #print(word_tokenize(text))\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tokenize=tokenizer.tokenize(sent)\n",
    "    tokenize=[a.lower() for a in tokenize]\n",
    "    sent_clean = []\n",
    "    for d in tokenize:\n",
    "        if (d not in stopwords_english and  # remove stopwords\n",
    "                d not in string.punctuation):# remove punctuation\n",
    "            #lem_sent=lemmatizer.lemmatize(d)\n",
    "            sent_clean.append(d)\n",
    "    return sent_clean\n",
    "    \n",
    "\n",
    "print(df1['text'].apply(process_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab are 437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'__PAD__': 0,\n",
       " '__</e>__': 1,\n",
       " '__UNK__': 2,\n",
       " 'hello': 3,\n",
       " 'apple': 4,\n",
       " 'product': 5,\n",
       " 'support': 6,\n",
       " 'yes': 7,\n",
       " 'may': 8,\n",
       " 'help': 9,\n",
       " 'understand': 10,\n",
       " 'situation': 11,\n",
       " 'glad': 12,\n",
       " 'assist': 13,\n",
       " 'please': 14,\n",
       " 'share': 15,\n",
       " 'order': 16,\n",
       " 'id': 17,\n",
       " 'let': 18,\n",
       " 'know': 19,\n",
       " 'would': 20,\n",
       " 'like': 21,\n",
       " 'return': 22,\n",
       " 'replacement': 23,\n",
       " 'request': 24,\n",
       " 'created': 25,\n",
       " 'carry': 26,\n",
       " 'device': 27,\n",
       " 'nearest': 28,\n",
       " 'store': 29,\n",
       " 'representatives': 30,\n",
       " 'verify': 31,\n",
       " 'replace': 32,\n",
       " 'thank': 33,\n",
       " 'good': 34,\n",
       " 'day': 35,\n",
       " 'welcome': 36,\n",
       " 'great': 37,\n",
       " 'today': 38,\n",
       " 'bank': 39,\n",
       " 'wealth': 40,\n",
       " 'name': 41,\n",
       " 'heather': 42,\n",
       " 'remaining': 43,\n",
       " 'money': 44,\n",
       " 'account': 45,\n",
       " 'iâ': 46,\n",
       " '\\x80': 47,\n",
       " '\\x99': 48,\n",
       " 'get': 49,\n",
       " 'number': 50,\n",
       " 'sure': 51,\n",
       " 'tracy': 52,\n",
       " 'q': 53,\n",
       " 'randall': 54,\n",
       " '8051-7845-': 55,\n",
       " '3895-0611': 56,\n",
       " 'check': 57,\n",
       " 'ok': 58,\n",
       " 'last': 59,\n",
       " 'four': 60,\n",
       " 'numbers': 61,\n",
       " 'social': 62,\n",
       " 'security': 63,\n",
       " 'still': 64,\n",
       " '84': 65,\n",
       " 'thousand': 66,\n",
       " '65': 67,\n",
       " 'cents': 68,\n",
       " 'anything': 69,\n",
       " 'else': 70,\n",
       " 'could': 71,\n",
       " 'transfer': 72,\n",
       " 'lloyds': 73,\n",
       " 'london': 74,\n",
       " 'long': 75,\n",
       " 'take': 76,\n",
       " 'transaction': 77,\n",
       " 'phone': 78,\n",
       " 'online': 79,\n",
       " 'team': 80,\n",
       " 'contact': 81,\n",
       " 'verification': 82,\n",
       " 'prior': 83,\n",
       " 'sending': 84,\n",
       " 'different': 85,\n",
       " 'whole': 86,\n",
       " 'process': 87,\n",
       " 'usually': 88,\n",
       " 'takes': 89,\n",
       " '2-3': 90,\n",
       " 'days': 91,\n",
       " 'see': 92,\n",
       " 'never': 93,\n",
       " 'mind': 94,\n",
       " 'holidays': 95,\n",
       " 'thanks': 96,\n",
       " 'agent': 97,\n",
       " 'much': 98,\n",
       " 'ms': 99,\n",
       " 'calling': 100,\n",
       " 'bye': 101,\n",
       " 'jones': 102,\n",
       " 'speaking': 103,\n",
       " 'asking': 104,\n",
       " 'trouble': 105,\n",
       " 'headset': 106,\n",
       " 'one': 107,\n",
       " 'side': 108,\n",
       " 'working': 109,\n",
       " 'specify': 110,\n",
       " 'want': 111,\n",
       " 'look': 112,\n",
       " 'mark': 113,\n",
       " 'placed': 114,\n",
       " 'latest': 115,\n",
       " 'version': 116,\n",
       " 'xbox': 117,\n",
       " 'wanted': 118,\n",
       " 'status': 119,\n",
       " '8265456366': 120,\n",
       " 'give': 121,\n",
       " 'minute': 122,\n",
       " 'back': 123,\n",
       " 'dispatched': 124,\n",
       " 'warehouse': 125,\n",
       " 'currently': 126,\n",
       " 'transit': 127,\n",
       " 'live': 128,\n",
       " 'updates': 129,\n",
       " 'moves': 130,\n",
       " 'definitely': 131,\n",
       " 'itâ': 132,\n",
       " 'feature': 133,\n",
       " 'letting': 134,\n",
       " 'set': 135,\n",
       " 'frequent': 136,\n",
       " 'reaches': 137,\n",
       " 'goes': 138,\n",
       " 'well': 139,\n",
       " 'reach': 140,\n",
       " 'us': 141,\n",
       " 'saturday': 142,\n",
       " 'wow': 143,\n",
       " 'new': 144,\n",
       " 'anticipated': 145,\n",
       " 'contacting': 146,\n",
       " 'henry': 147,\n",
       " 'going': 148,\n",
       " 'assistance': 149,\n",
       " 'reset': 150,\n",
       " 'confirm': 151,\n",
       " 'email': 152,\n",
       " 'address': 153,\n",
       " 'mail': 154,\n",
       " 'hellohenry@gmail.com': 155,\n",
       " '6543215485': 156,\n",
       " 'sounds': 157,\n",
       " 'sent': 158,\n",
       " 'link': 159,\n",
       " 'along': 160,\n",
       " 'instructions': 161,\n",
       " 'receive': 162,\n",
       " '..': 163,\n",
       " 'received': 164,\n",
       " 'instruction': 165,\n",
       " 'password': 166,\n",
       " 'looks': 167,\n",
       " 'perfect': 168,\n",
       " 'believe': 169,\n",
       " 'needed': 170,\n",
       " 'kind': 171,\n",
       " 'highly': 172,\n",
       " 'appreciate': 173,\n",
       " 'pleasure': 174,\n",
       " 'serving': 175,\n",
       " 'joe': 176,\n",
       " 'hope': 177,\n",
       " 'fine': 178,\n",
       " '9490403': 179,\n",
       " '00': 180,\n",
       " 'jimmy': 181,\n",
       " 'chap': 182,\n",
       " 'state': 183,\n",
       " 'error': 184,\n",
       " 'says': 185,\n",
       " 'first': 186,\n",
       " 'feel': 187,\n",
       " 'moved': 188,\n",
       " 'application': 189,\n",
       " 'onto': 190,\n",
       " 'remote': 191,\n",
       " 'servers': 192,\n",
       " 'hve': 193,\n",
       " '48giggs': 194,\n",
       " 'memory': 195,\n",
       " 'seems': 196,\n",
       " 'sufficient': 197,\n",
       " 'mike': 198,\n",
       " 'bot': 199,\n",
       " 'brian': 200,\n",
       " \"i'll\": 201,\n",
       " 'happy': 202,\n",
       " 'allow': 203,\n",
       " 'moment': 204,\n",
       " 'course': 205,\n",
       " 'time': 206,\n",
       " 'correct': 207,\n",
       " 'sorry': 208,\n",
       " 'delay': 209,\n",
       " 'must': 210,\n",
       " 'lost': 211,\n",
       " 'shipping': 212,\n",
       " 'create': 213,\n",
       " '8488422': 214,\n",
       " '5': 215,\n",
       " 'worries': 216,\n",
       " 'seamless': 217,\n",
       " 'easy': 218,\n",
       " 'make': 219,\n",
       " 'recommendation': 220,\n",
       " 'reddit': 221,\n",
       " 'tell': 222,\n",
       " 'friends': 223,\n",
       " 'nice': 224,\n",
       " 'went': 225,\n",
       " 'hi': 226,\n",
       " 'james': 227,\n",
       " 'chat': 228,\n",
       " 'peter': 229,\n",
       " '00094830': 230,\n",
       " '21': 231,\n",
       " 'information': 232,\n",
       " 'also': 233,\n",
       " 'entered': 234,\n",
       " 'right': 235,\n",
       " '12390': 236,\n",
       " 'mulberry': 237,\n",
       " 'ln': 238,\n",
       " 'coral': 239,\n",
       " 'springs': 240,\n",
       " 'fl': 241,\n",
       " '33067': 242,\n",
       " 'shipped': 243,\n",
       " 'problem': 244,\n",
       " 'youâ': 245,\n",
       " 'go': 246,\n",
       " 'nope': 247,\n",
       " 'thatâ': 248,\n",
       " 'customer': 249,\n",
       " 'toycityinc': 250,\n",
       " 'â': 251,\n",
       " '\\x93': 252,\n",
       " 'daughter': 253,\n",
       " 'birthday': 254,\n",
       " 'products': 255,\n",
       " 'purchased': 256,\n",
       " 'iphone': 257,\n",
       " '10': 258,\n",
       " 'week': 259,\n",
       " 'started': 260,\n",
       " 'overheat': 261,\n",
       " '5456972': 262,\n",
       " '3': 263,\n",
       " 'serious': 264,\n",
       " 'month': 265,\n",
       " 'ago': 266,\n",
       " 'sir': 267,\n",
       " 'system': 268,\n",
       " 'shows': 269,\n",
       " 'purchase': 270,\n",
       " 'january': 271,\n",
       " 'annoying': 272,\n",
       " 'second': 273,\n",
       " 'facing': 274,\n",
       " 'bad': 275,\n",
       " 'experience': 276,\n",
       " 'connect': 277,\n",
       " 'manager': 278,\n",
       " 'ridiculous': 279,\n",
       " 'said': 280,\n",
       " 'need': 281,\n",
       " 'escalated': 282,\n",
       " 'indeed': 283,\n",
       " 'forgot': 284,\n",
       " 'xffinity': 285,\n",
       " 'locked': 286,\n",
       " 'access': 287,\n",
       " 'skin': 288,\n",
       " 'cream': 289,\n",
       " 'smell': 290,\n",
       " 'feels': 291,\n",
       " 'wierd': 292,\n",
       " 'particularly': 293,\n",
       " 'called': 294,\n",
       " 'refund': 295,\n",
       " 'exchange': 296,\n",
       " 'accidentally': 297,\n",
       " 'applied': 298,\n",
       " 'caused': 299,\n",
       " 'allergic': 300,\n",
       " 'reaction': 301,\n",
       " 'acceptable': 302,\n",
       " 'ways': 303,\n",
       " 'really': 304,\n",
       " 'service': 305,\n",
       " 'expected': 306,\n",
       " 'taken': 307,\n",
       " 'managers': 308,\n",
       " 'notice': 309,\n",
       " 'people': 310,\n",
       " 'harmed': 311,\n",
       " 'alert': 312,\n",
       " 'higher': 313,\n",
       " 'authorities': 314,\n",
       " 'immediately': 315,\n",
       " 'stop': 316,\n",
       " 'sale': 317,\n",
       " 'line': 318,\n",
       " 'trying': 319,\n",
       " 'use': 320,\n",
       " 'applications': 321,\n",
       " 'index': 322,\n",
       " 'crashes': 323,\n",
       " 'rather': 324,\n",
       " 'simple': 325,\n",
       " 'function': 326,\n",
       " 'computer': 327,\n",
       " 'wrong': 328,\n",
       " 'ran': 329,\n",
       " 'server': 330,\n",
       " 'issue': 331,\n",
       " 'done': 332,\n",
       " 'keep': 333,\n",
       " 'blame': 334,\n",
       " 'game': 335,\n",
       " 'usual': 336,\n",
       " 'accept': 337,\n",
       " 'mistakes': 338,\n",
       " 'row': 339,\n",
       " 'getting': 340,\n",
       " 'response': 341,\n",
       " 'guys': 342,\n",
       " 'unsubscribe': 343,\n",
       " 'license': 344,\n",
       " 'discourage': 345,\n",
       " 'others': 346,\n",
       " 'using': 347,\n",
       " 'providing': 348,\n",
       " 'automatic': 349,\n",
       " 'irobot': 350,\n",
       " 'home': 351,\n",
       " 'vacuum': 352,\n",
       " 'run': 353,\n",
       " 'straight': 354,\n",
       " 'crashing': 355,\n",
       " 'wall': 356,\n",
       " 'without': 357,\n",
       " 'automatically': 358,\n",
       " 'sensing': 359,\n",
       " 'crack': 360,\n",
       " 'sides': 361,\n",
       " 'due': 362,\n",
       " 'fault': 363,\n",
       " 'broken': 364,\n",
       " 'think': 365,\n",
       " 'broke': 366,\n",
       " \"its's\": 367,\n",
       " 'unhappy': 368,\n",
       " 'premium': 369,\n",
       " 'membership': 370,\n",
       " 'substandard': 371,\n",
       " 'unfair': 372,\n",
       " 'disappointing': 373,\n",
       " 'delivered': 374,\n",
       " 'quite': 375,\n",
       " 'send': 376,\n",
       " 'low': 377,\n",
       " 'quality': 378,\n",
       " 'general': 379,\n",
       " 'delivery': 380,\n",
       " 'certainly': 381,\n",
       " 'improvement': 382,\n",
       " 'next': 383,\n",
       " 'another': 384,\n",
       " 'two': 385,\n",
       " 'shampoos': 386,\n",
       " 'added': 387,\n",
       " 'cart': 388,\n",
       " 'screen': 389,\n",
       " '2': 390,\n",
       " 'quantites': 391,\n",
       " 'shampoo': 392,\n",
       " 'ordered': 393,\n",
       " 'got': 394,\n",
       " 'donâ': 395,\n",
       " 'suppose': 396,\n",
       " 'mistake': 397,\n",
       " 'stores': 398,\n",
       " 'near': 399,\n",
       " 'reason': 400,\n",
       " 'disappoints': 401,\n",
       " 'impression': 402,\n",
       " 'leaves': 403,\n",
       " 'cause': 404,\n",
       " 'talk': 405,\n",
       " 'explain': 406,\n",
       " 'entire': 407,\n",
       " 'scenario': 408,\n",
       " 'frustrating': 409,\n",
       " 'alright': 410,\n",
       " 'ahead': 411,\n",
       " 'someone': 412,\n",
       " 'gmail': 413,\n",
       " 'associate': 414,\n",
       " 'delete': 415,\n",
       " 'brittni': 416,\n",
       " 'chris': 417,\n",
       " 'williams': 418,\n",
       " 'actual': 419,\n",
       " 'ctwillixxx@gmail.com': 420,\n",
       " 'ct.willixxx@gmail.com': 421,\n",
       " 'sort': 422,\n",
       " 'phishing': 423,\n",
       " 'attempt': 424,\n",
       " 'real': 425,\n",
       " 'yah': 426,\n",
       " 'im': 427,\n",
       " 'taking': 428,\n",
       " 'wait': 429,\n",
       " 'okay': 430,\n",
       " '...': 431,\n",
       " 'mine': 432,\n",
       " 'change': 433,\n",
       " 'maam': 434,\n",
       " 'resolve': 435,\n",
       " 'say': 436}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the vocabulary\n",
    "# Unit Test Note - There is no test set here only train/val\n",
    "\n",
    "# Include special tokens \n",
    "# started with pad, end of line and unk tokens\n",
    "Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2} \n",
    "\n",
    "# Note that we build vocab using training data\n",
    "for sent in train_x: \n",
    "    process_sent = process_text(sent)\n",
    "    for word in process_sent:\n",
    "        if word not in Vocab: \n",
    "            Vocab[word] = len(Vocab)\n",
    "    \n",
    "print(\"Total words in vocab are\",len(Vocab))\n",
    "display(Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED FUNCTION: sent_to_tensor\n",
    "def sent_to_tensor(sent, vocab_dict, unk_token='__UNK__', verbose=False):\n",
    "    '''\n",
    "    Input: \n",
    "        sent - A string containing a sentence\n",
    "        vocab_dict - The words dictionary\n",
    "        unk_token - The special string for unknown tokens\n",
    "        verbose - Print info durign runtime\n",
    "    Output:\n",
    "        tensor_l - A python list with\n",
    "        \n",
    "    '''  \n",
    "    \n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    # Process the sentence into a list of words\n",
    "    # where only important words are kept (stop words removed)\n",
    "    word_l = process_text(sent)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"List of words from the processed sentence:\")\n",
    "        print(word_l)\n",
    "        \n",
    "    # Initialize the list that will contain the unique integer IDs of each word\n",
    "    tensor_l = []\n",
    "    \n",
    "    # Get the unique integer ID of the __UNK__ token\n",
    "    unk_ID = Vocab.get('__UNK__')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
    "        \n",
    "    # for each word in the list:\n",
    "    for word in word_l:\n",
    "        \n",
    "        # Get the unique integer ID.\n",
    "        # If the word doesn't exist in the vocab dictionary,\n",
    "        # use the unique ID for __UNK__ instead.\n",
    "        word_ID = vocab_dict.get(word,unk_ID)\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "        # Append the unique integer ID to the tensor list.\n",
    "        tensor_l.append(word_ID) \n",
    "    \n",
    "    return tensor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sentence is\n",
      " Yes I can help you. Could you please share me your order id \n",
      "\n",
      "Tensor of sentence:\n",
      " [7, 9, 71, 14, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual sentence is\\n\", val_pos[1])\n",
    "print(\"\\nTensor of sentence:\\n\", sent_to_tensor(val_pos[1], vocab_dict=Vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# test sent_to_tensor\n",
    "\n",
    "def test_sent_to_tensor():\n",
    "    test_cases = [\n",
    "        \n",
    "        {\n",
    "            \"name\":\"simple_test_check\",\n",
    "            \"input\": [val_pos[1], Vocab],\n",
    "            \"expected\":[7, 9, 71, 14, 15, 16, 17],\n",
    "            \"error\":\"The function gives bad output for val_pos[1]. Test failed\"\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"datatype_check\",\n",
    "            \"input\":[val_pos[1], Vocab],\n",
    "            \"expected\":type([]),\n",
    "            \"error\":\"Datatype mismatch. Need only list not np.array\"\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"without_unk_check\",\n",
    "            \"input\":[val_pos[1], Vocab],\n",
    "            \"expected\":6,\n",
    "            \"error\":\"Unk word check not done- Please check if you included mapping for unknown word\"\n",
    "        }\n",
    "    ]\n",
    "    count = 0\n",
    "    for test_case in test_cases:\n",
    "        \n",
    "        try:\n",
    "            if test_case['name'] == \"simple_test_check\":\n",
    "                assert test_case[\"expected\"] == sent_to_tensor(*test_case['input'])\n",
    "                count += 1\n",
    "            if test_case['name'] == \"datatype_check\":\n",
    "                assert isinstance(sent_to_tensor(*test_case['input']), test_case[\"expected\"])\n",
    "                count += 1\n",
    "            if test_case['name'] == \"without_unk_check\":\n",
    "                assert None not in sent_to_tensor(*test_case['input'])\n",
    "                count += 1\n",
    "                \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(test_case['error'])\n",
    "    if count == 3:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(count,\" Tests passed out of 3\")\n",
    "test_sent_to_tensor()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_pos, data_neg, batch_size, loop, vocab_dict, shuffle=False):\n",
    "    '''\n",
    "    Input: \n",
    "        data_pos - Set of posstive examples\n",
    "        data_neg - Set of negative examples\n",
    "        batch_size - number of samples per batch. Must be even\n",
    "        loop - True or False\n",
    "        vocab_dict - The words dictionary\n",
    "        shuffle - Shuffle the data order\n",
    "    Yield:\n",
    "        inputs - Subset of positive and negative examples\n",
    "        targets - The corresponding labels for the subset\n",
    "        example_weights - An array specifying the importance of each example\n",
    "        \n",
    "    '''     \n",
    "### START GIVEN CODE ###\n",
    "    # make sure the batch size is an even number\n",
    "    # to allow an equal number of positive and negative samples\n",
    "    assert batch_size % 2 == 0\n",
    "    \n",
    "    # Number of positive examples in each batch is half of the batch size\n",
    "    # same with number of negative examples in each batch\n",
    "    n_to_take = batch_size // 2\n",
    "    \n",
    "    \n",
    "    # Use pos_index to walk through the data_pos array\n",
    "    # same with neg_index and data_neg\n",
    "    pos_index = 0\n",
    "    neg_index = 0\n",
    "    \n",
    "    len_data_pos = len(data_pos)\n",
    "    len_data_neg = len(data_neg)\n",
    "   \n",
    "    \n",
    "    # Get and array with the data indexes\n",
    "    pos_index_lines = list(range(len_data_pos))\n",
    "    neg_index_lines = list(range(len_data_neg))\n",
    "    \n",
    "    # shuffle lines if shuffle is set to True\n",
    "    if shuffle:\n",
    "        rnd.shuffle(pos_index_lines)\n",
    "        rnd.shuffle(neg_index_lines)\n",
    "        \n",
    "    stop = False\n",
    "    \n",
    "    # Loop indefinitely\n",
    "    while not stop:  \n",
    "        \n",
    "        # create a batch with positive and negative examples\n",
    "        batch = []\n",
    "        \n",
    "        # First part: Pack n_to_take positive examples\n",
    "        \n",
    "        # Start from pos_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "                    \n",
    "            # If the positive index goes past the positive dataset lenght,\n",
    "            if pos_index >= len_data_pos: \n",
    "                \n",
    "                # If loop is set to False, break once we reach the end of the dataset\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "                \n",
    "                # If user wants to keep re-using the data, reset the index\n",
    "                pos_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    # Shuffle the index of the positive sample\n",
    "                    rnd.shuffle(pos_index_lines)\n",
    "                    \n",
    "            # get the sentence as pos_index\n",
    "            sent = data_pos[pos_index_lines[pos_index]]\n",
    "           \n",
    "            # convert the sentence into tensors of integers representing the processed words\n",
    "            tensor = sent_to_tensor(sent, vocab_dict)\n",
    "           \n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "            \n",
    "            # Increment pos_index by one\n",
    "            pos_index = pos_index + 1\n",
    "\n",
    "### END GIVEN CODE ###\n",
    "            \n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "\n",
    "        # Second part: Pack n_to_take negative examples\n",
    "    \n",
    "        # Using the same batch list, start from neg_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "            \n",
    "            # If the negative index goes past the negative dataset length,\n",
    "            if neg_index >=len_data_neg:\n",
    "                \n",
    "                # If loop is set to False, break once we reach the end of the dataset\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "                    \n",
    "                # If user wants to keep re-using the data, reset the index\n",
    "                neg_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    # Shuffle the index of the negative sample\n",
    "                    rnd.shuffle(neg_index_lines)\n",
    "            # get the sntence as neg_index\n",
    "            sent = data_neg[neg_index_lines[neg_index]]\n",
    "            \n",
    "            # convert the sentence into tensors of integers representing the processed words\n",
    "            tensor = sent_to_tensor(sent,vocab_dict)\n",
    "            \n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "            \n",
    "            # Increment neg_index by one\n",
    "            neg_index = neg_index+1\n",
    "            \n",
    "### END CODE HERE ###        \n",
    "\n",
    "### START GIVEN CODE ###\n",
    "        if stop:\n",
    "            break;\n",
    "\n",
    "        # Update the start index for positive data \n",
    "        # so that it's n_to_take positions after the current pos_index\n",
    "        pos_index += n_to_take\n",
    "        \n",
    "        # Update the start index for negative data \n",
    "        # so that it's n_to_take positions after the current neg_index\n",
    "        neg_index += n_to_take\n",
    "        \n",
    "        # Get the max sentence length (the length of the longest sentence) \n",
    "        # (you will pad all shorter sentences to have this length)\n",
    "        max_len = max([len(t) for t in batch]) \n",
    "        \n",
    "        \n",
    "        # Initialize the input_l, which will d \n",
    "        # store the padded versions of the tensors\n",
    "        tensor_pad_l = []\n",
    "        # Pad shorter sentences with zeros\n",
    "        for tensor in batch:\n",
    "### END GIVEN CODE ###\n",
    "\n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "            # Get the number of positions to pad for this tensor so that it will be max_len long\n",
    "            n_pad = max_len - len(tensor)\n",
    "            \n",
    "            # Generate a list of zeros, with length n_pad\n",
    "            pad_l = [0] * n_pad\n",
    "            \n",
    "            # concatenate the tensor and the list of padded zeros\n",
    "            tensor_pad = tensor + pad_l \n",
    "            \n",
    "            # append the padded tensor to the list of padded tensors\n",
    "            tensor_pad_l.append(tensor_pad)\n",
    "\n",
    "        # convert the list of padded tensors to a numpy array\n",
    "        # and store this as the model inputs\n",
    "        inputs = np.array(tensor_pad_l)\n",
    "  \n",
    "        # Generate the list of targets for the positive examples (a list of ones)\n",
    "        # The length is the number of positive examples in the batch\n",
    "        target_pos =  [1]*n_to_take\n",
    "        \n",
    "        # Generate the list of targets for the negative examples (a list of zeros)\n",
    "        # The length is the number of negative examples in the batch\n",
    "        target_neg = [0]*n_to_take\n",
    "        \n",
    "        # Concatenate the positve and negative targets\n",
    "        target_l = target_pos+target_neg\n",
    "        \n",
    "        # Convert the target list into a numpy array\n",
    "        targets = np.array(target_l)\n",
    "        \n",
    "        # Example weights: Treat all examples equally importantly.It should return an np.array. Hint: Use np.ones_like()\n",
    "        example_weights = np.ones_like(targets)\n",
    "        \n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "### GIVEN CODE ###\n",
    "        # note we use yield and not return\n",
    "        yield inputs, targets, example_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[ 92  93  94  95  96   9  42   0   0   0   0   0   0   0   0]\n",
      " [186 187 188 189 190 191 192 193 194 195 196 197  64  92 184]\n",
      " [434   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Targets: [1 1 0 0]\n",
      "Example Weights: [1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Set the random number generator for the shuffle procedure\n",
    "rnd.seed(30) \n",
    "\n",
    "# Create the training data generator\n",
    "def train_generator(batch_size, shuffle = False):\n",
    "    return data_generator(train_pos, train_neg, batch_size, True, Vocab, shuffle)\n",
    "\n",
    "# Create the validation data generator\n",
    "def val_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, True, Vocab, shuffle)\n",
    "\n",
    "# Create the validation data generator\n",
    "def test_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, False, Vocab, shuffle)\n",
    "\n",
    "# Get a batch from the train_generator and inspect.\n",
    "inputs, targets, example_weights = next(train_generator(4, shuffle=True))\n",
    "\n",
    "# this will print a list of 4 tensors padded with zeros\n",
    "print(f'Inputs: {inputs}')\n",
    "print(f'Targets: {targets}')\n",
    "print(f'Example Weights: {example_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs shape is (4, 6)\n",
      "The targets shape is (4,)\n",
      "The example weights shape is (4,)\n",
      "input tensor: [3 4 5 6 0 0]; target 1; example weights 1\n",
      "input tensor: [7 8 9 0 0 0]; target 1; example weights 1\n",
      "input tensor: [244 107 255 256  29   0]; target 0; example weights 1\n",
      "input tensor: [257 258 259  78 260 261]; target 0; example weights 1\n"
     ]
    }
   ],
   "source": [
    "# Test the train_generator\n",
    "\n",
    "# Create a data generator for training data,\n",
    "# which produces batches of size 4 (for tensors and their respective targets)\n",
    "tmp_data_gen = train_generator(batch_size = 4)\n",
    "\n",
    "# Call the data generator to get one batch and its targets\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = next(tmp_data_gen)\n",
    "\n",
    "print(f\"The inputs shape is {tmp_inputs.shape}\")\n",
    "print(f\"The targets shape is {tmp_targets.shape}\")\n",
    "print(f\"The example weights shape is {tmp_example_weights.shape}\")\n",
    "\n",
    "for i,t in enumerate(tmp_inputs):\n",
    "    print(f\"input tensor: {t}; target {tmp_targets[i]}; example weights {tmp_example_weights[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"Base class for layers.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "  \n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        pass\n",
    "\n",
    "    def init(self, input_signature, random_key):\n",
    "        self.init_weights_and_state(input_signature, random_key)\n",
    "        return self.weights\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Layer):\n",
    "    \"\"\"Relu activation function implementation\"\"\"\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input: \n",
    "            - x (a numpy array): the input\n",
    "        Output:\n",
    "            - activation (numpy array): all positive or 0 version of x\n",
    "        '''\n",
    "        ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "        \n",
    "        activation = np.maximum(x,0)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the fastmath module within trax\n",
    "from trax import fastmath\n",
    "\n",
    "# use the numpy module from trax\n",
    "np = fastmath.numpy\n",
    "\n",
    "# use the fastmath.random module from trax\n",
    "random = fastmath.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    \"\"\"\n",
    "    A dense (fully-connected) layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # __init__ is implemented for you\n",
    "    def __init__(self, n_units, init_stdev=0.1):\n",
    "        \n",
    "        # Set the number of units in this layer\n",
    "        self._n_units = n_units\n",
    "        self._init_stdev = init_stdev\n",
    "\n",
    "    # Please implement 'forward()'\n",
    "    def forward(self, x):\n",
    "\n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "\n",
    "        # Matrix multiply x and the weight matrix\n",
    "        dense = np.dot(x,self.weights) \n",
    "        \n",
    "### END CODE HERE ###\n",
    "        return dense\n",
    "\n",
    "    # init_weights\n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        \n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "        # The input_signature has a .shape attribute that gives the shape as a tuple\n",
    "        input_shape = (input_signature.shape[-1], self._n_units)\n",
    "\n",
    "        # Generate the weight matrix from a normal distribution, \n",
    "        # and standard deviation of 'stdev'        \n",
    "        w = trax.fastmath.random.normal(key=random_key, shape=input_shape) * self._init_stdev\n",
    "        \n",
    "### END CODE HERE ###     \n",
    "        self.weights = w\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights are\n",
      "  [[-0.02837108  0.09368162 -0.10050076  0.14165013  0.10543301  0.09108126\n",
      "  -0.04265672  0.0986188  -0.05575325  0.00153249]\n",
      " [-0.20785688  0.0554837   0.09142365  0.05744595  0.07227863  0.01210617\n",
      "  -0.03237354  0.16234995  0.02450038 -0.13809784]\n",
      " [-0.06111237  0.01403724  0.08410042 -0.1094358  -0.10775021 -0.11396459\n",
      "  -0.05933381 -0.01557652 -0.03832145 -0.11144515]]\n",
      "Foward function output is  [[-3.0395496   0.9266802   2.5414743  -2.050473   -1.9769388  -2.582209\n",
      "  -1.7952735   0.94427425 -0.8980402  -3.7497487 ]]\n"
     ]
    }
   ],
   "source": [
    "# Testing your Dense layer \n",
    "dense_layer = Dense(n_units=10)  #sets  number of units in dense layer (n_units=10)\n",
    "random_key = random.get_prng(seed=0)  # sets random seed\n",
    "z = np.array([[2.0, 7.0, 25.0]]) # input array \n",
    "\n",
    "dense_layer.init(z, random_key)\n",
    "print(\"Weights are\\n \",dense_layer.weights) #Returns randomly generated weights\n",
    "print(\"Foward function output is \", dense_layer(z)) # Returns multiplied values of units and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: classifier\n",
    "def classifier(vocab_size=len(Vocab), embedding_dim=256, output_dim=2, mode='train'):\n",
    "        \n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    # create embedding layer\n",
    "    embed_layer = tl.Embedding(\n",
    "        vocab_size=vocab_size, # Size of the vocabulary\n",
    "        d_feature=embedding_dim)  # Embedding dimension\n",
    "    \n",
    "    # Create a mean layer, to create an \"average\" word embedding\n",
    "    mean_layer = tl.Mean(axis=1)\n",
    "    \n",
    "    # Create a dense layer, one unit for each output\n",
    "    dense_output_layer = tl.Dense(n_units = output_dim)\n",
    "\n",
    "    \n",
    "    # Create the log softmax layer (no parameters needed)\n",
    "    softmax_layer = tl.Softmax()\n",
    "    \n",
    "    # Use tl.Serial to combine all layers\n",
    "    # and create the classifier\n",
    "    # of type trax.layers.combinators.Serial\n",
    "    model = tl.Serial(\n",
    "      embed_layer, # embedding layer\n",
    "      mean_layer, # mean layer\n",
    "      dense_output_layer, # dense output layer \n",
    "      softmax_layer # log softmax layer\n",
    "    )\n",
    "### END CODE HERE ###     \n",
    "    \n",
    "    # return the model of type\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'trax.layers.combinators.Serial'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  Embedding_437_256\n",
       "  Mean\n",
       "  Dense_2\n",
       "  Softmax\n",
       "]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(tmp_model))\n",
    "display(tmp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "batch_size = 16\n",
    "rnd.seed(271)\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_generator(batch_size=batch_size, shuffle=True),\n",
    "    loss_layer=tl.WeightedCategoryCrossEntropy(),\n",
    "    optimizer=trax.optimizers.Adam(0.01),\n",
    "    n_steps_per_checkpoint=20,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=val_generator(batch_size=batch_size, shuffle=True),\n",
    "    metrics=[tl.WeightedCategoryCrossEntropy(), tl.WeightedCategoryAccuracy()],\n",
    ")\n",
    "\n",
    "model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lexroverts/model/\n"
     ]
    }
   ],
   "source": [
    "output_dir = '~/model/'\n",
    "output_dir_expand = os.path.expanduser(output_dir)\n",
    "print(output_dir_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_model\n",
    "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
    "    '''\n",
    "    Input: \n",
    "        classifier - the model you are building\n",
    "        train_task - Training task\n",
    "        eval_task - Evaluation task\n",
    "        n_steps - the evaluation steps\n",
    "        output_dir - folder to save your files\n",
    "    Output:\n",
    "        trainer -  trax trainer\n",
    "    '''\n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    training_loop = training.Loop(\n",
    "                                classifier, # The learning model\n",
    "                                train_task, # The training task\n",
    "                                eval_tasks = [eval_task], # The evaluation task\n",
    "                                output_dir = output_dir) # The output directory\n",
    "\n",
    "    training_loop.run(n_steps = n_steps)\n",
    "### END CODE HERE ###\n",
    "\n",
    "    # Return the training_loop, since it has the model.\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step   1340: Ran 20 train steps in 8.00 secs\n",
      "Step   1340: train WeightedCategoryCrossEntropy |  0.33322650\n",
      "Step   1340: eval  WeightedCategoryCrossEntropy |  0.68531901\n",
      "Step   1340: eval      WeightedCategoryAccuracy |  0.62500000\n"
     ]
    }
   ],
   "source": [
    "training_loop = train_model(model, train_task, eval_task,100, output_dir_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_accuracy\n",
    "def compute_accuracy(preds, y, y_weights):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        preds: a tensor of shape (dim_batch, output_dim) \n",
    "        y: a tensor of shape (dim_batch,) with the true labels\n",
    "        y_weights: a n.ndarray with the a weight for each example\n",
    "    Output: \n",
    "        accuracy: a float between 0-1 \n",
    "        weighted_num_correct (np.float32): Sum of the weighted correct predictions\n",
    "        sum_weights (np.float32): Sum of the weights\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    # Create an array of booleans, \n",
    "    # True if the probability of positive sentiment is greater than\n",
    "    # the probability of negative sentiment\n",
    "    # else False\n",
    "    is_pos =  preds[:,1] > preds[:,0]\n",
    "\n",
    "    # convert the array of booleans into an array of np.int32\n",
    "    is_pos_int = is_pos.astype(np.int32)\n",
    "    \n",
    "    # compare the array of predictions (as int32) with the target (labels) of type int32\n",
    "    correct = np.equal(is_pos_int, y)\n",
    "\n",
    "    # Count the sum of the weights.\n",
    "    sum_weights = np.sum(y_weights)\n",
    "    \n",
    "    # convert the array of correct predictions (boolean) into an arrayof np.float32\n",
    "    correct_float = correct.astype(np.float32)\n",
    "    \n",
    "    # Multiply each prediction with its corresponding weight.\n",
    "    weighted_correct_float = correct_float*sum_weights\n",
    "\n",
    "    # Sum up the weighted correct predictions (of type np.float32), to go in the\n",
    "    # denominator.\n",
    "    weighted_num_correct = np.sum(correct_float)\n",
    " \n",
    "    # Divide the number of weighted correct predictions by the sum of the\n",
    "    # weights.\n",
    "    accuracy =   weighted_num_correct/sum_weights\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return accuracy, weighted_num_correct, sum_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's prediction accuracy on a single training batch is: 80.0%\n",
      "Weighted number of correct predictions 8.0; weighted number of total observations predicted 10\n"
     ]
    }
   ],
   "source": [
    "# test your function (64)\n",
    "tmp_val_generator = val_generator(10)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_val_generator)\n",
    "\n",
    "# Position 0 has the model inputs (sentence as tensors)\n",
    "# position 1 has the targets (the actual labels)\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch\n",
    "\n",
    "# feed the sentence tensors into the model to get a prediction\n",
    "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
    "\n",
    "tmp_acc, tmp_num_correct, tmp_num_predictions = compute_accuracy(preds=tmp_pred, y=tmp_targets, y_weights=tmp_example_weights)\n",
    "\n",
    "print(f\"Model's prediction accuracy on a single training batch is: {100 * tmp_acc}%\")\n",
    "print(f\"Weighted number of correct predictions {tmp_num_correct}; weighted number of total observations predicted {tmp_num_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example input_str: Hello, is this apple product support?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Yes, it is. How may I help you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I understand the situation and I am glad to assist you with it, can you please share the order id and let me know if you would like to have a return or replacement for it.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: A replacement request has been created, please carry the device to the nearest store and our representatives will verify and replace the product.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Thank you for you help, have a good day\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: You're welcome, have a great day!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: It is a good day today at Bank of Wealth. My name is Heather. How can I he you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I would like to know my remaining money in my account.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Iâll be glad to help you. May I please get your Bank Account number  and the Name on the Account?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Sure, it is Tracy Q. Randall. Account number is 8051-7845-3895-0611\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Thank you. let me just check on it. Ok. can you please. Verify the last four numbers of your social security ID?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: You still have 84 thousand and 65 cents. Is there anything else that I could assist you with?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Yes. If transfer I to my bank account in Lloyds of London. how long will take?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str:  If we do the transaction over the phone or online. Our team will still contact you for verification prior to sending your money to a different bank. The whole process usually just takes 2-3 days.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I see. never mind. I will just do it after the holidays. Thanks for your help, Heather!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Agent: You are very much welcome. Ms. Randall! You have a great day and Thank you for calling Bank of Wealth. Good Bye!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello Jones, this is May speaking. How may I assist you today?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello May, thanks for asking. I have a trouble with my headset. One side of it is not working.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I can help you with that, can you specify the order number?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Is there anything else you would want me to take a look into?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello Mark, how are you doing and how may I help you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I had placed an order at your store for an latest version of xbox. Wanted to check on the status of the order.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Sure, I can take a look for you. Can you please share the order number.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Why not, it is 8265456366\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Thank you for that, please give me a minute and I will get back. The order has been dispatched from the warehouse. Currently it is in transit. Would you like to have live updates on your phone as the order moves?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Definitely, itâs a good feature that is letting me know where my order is.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: You are all set, you will now get frequent updates as the order reaches our store. If all goes well, the order will reach us by Saturday.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Wow, that is good new as anticipated. Thank you for you support.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: You are welcome, have a great day!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: You as well!. Thank you contacting Support.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello Henry, How is your day going?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Sure, I am here for you assistance. Before I can reset, can you please confirm your email address and phone number please.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Yes, my mail address is hellohenry@gmail.com and phone number is 6543215485\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Great, that sounds good. I have sent an email reset link to you along with instructions to reset the account. Did you receive the email..\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Yes I received your mail and instruction to reset the password. It looks good and perfect.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Is there anything else that I can help you with.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I believe that is all I needed. Thank you for your kind assistance and help. Highly appreciate.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: It is pleasure serving you, have a great day!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Thank you, you too!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello Joe, hope you are having a fine day. How may I help you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Yes it is 949040300.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello Jimmy, this is Chap. How may I help you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Sure, can you please state what the error says?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: At first I did feel the same, but I moved the application onto a remote servers that hve 48Giggs memory. Which seems more the sufficient and I still see the same error.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello Mike, this is Bot. How can I help you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Sure, can you please state why you would want a replacement.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hello, my name is Brian. I'll be happy to help you today.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Thank you. Allow me a moment please.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Of course, take your time\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Yes, you are correct.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Sorry for the delay, it must have been lost in shipping.I'll just create a new order for this with one day shipping. The replacement order number is 84884225.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Great, thank you!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: No worries. thank you again! that was seamless and easy. I'll be sure to make a recommendation on reddit and tell all my friends how nice and easy this went. have a great day.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: You very much welcome, hope you have a great day!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hi James, welcome to Live Chat! My name is Peter. How can I help you today?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Hi, I wanted to check my order status. My order number is 0009483021.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Great, thanks for the information! Give me one moment please while I check on that for you.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Great, thank you! Yes, I also wanted to make sure I entered the right shipping address. My address is 12390 Mulberry Ln, Coral Springs, FL 33067. Is that where itâs being shipped to?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: No problem, let me check that for you. Yes, I have here the shipping address as 12390 Mulberry Ln, Coral Springs, FL 33067. It looks like youâre good to go!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Thanks so much!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Not a problem! Is there anything else I can do for you?\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Nope, thatâs it\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Great, Iâm glad I could help you!! Thanks for being a customer of ToyCityInc. â We hope your daughter has a very happy birthday!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I appreciate it!\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: I have a problem with one of the products that I have purchased at your store\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: It is an iphone 10, it has been a week about now and the phone has started to overheat.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: My order id is 54569723 and I would like to have a replacement\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Hello May, thanks for asking. I have a trouble with my headset. One side of it is not working.\n",
      "Model returned sentiment probabilities: [1]\n",
      "example input_str: Are you serious, I have just purchased this a month ago.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Sorry Sir, but the system shows the purchase as last January.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: That is very annoying , this is the second time that I am facing a bad experience with your customer support. Can you connect me to your manager?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: This is ridiculous, I said connect me to your manager. I need to get this escalated.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: It is going bad indeed. I forgot my password to the xffinity account and now the system has locked me out. Can you help me get my access back.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Hello, I had purchased a skin cream the other day at your store and it has different smell and feels wierd.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I have not particularly called for a refund or exchange. I had accidentally applied the cream and it has caused a serious allergic reaction on my skin. This is not acceptable in any ways.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: This is a really bad service and one not expected from a store like yours. This problem must be taken to the managers notice. Connect me to your manager before other people get harmed, I need to alert higher authorities to immediately stop the sale of those products.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Sure, I will be on the line.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I need help with an error when trying to use one of your applications feature.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: It says index out of memory and the application crashes.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: That is a rather simple function and should not take much memory. There seems to be a problem with your computer.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: NO, the problem is not with my computer. You are wrong, as I have ran it on the server as well, but the issue is still on.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I am done with this, at your customer service you keep doing the blame game as usual. Never accept mistakes. This is the second time in a row that I am getting this bad response from you guys. I want to unsubscribe the license and discourage others from using your products for the kind of service you are providing.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Hello Bot, I need to replace the automatic irobot home vacuum that I purchased the other day.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: On its first run, it went straight crashing into the wall without automatically sensing and it now has a crack on the sides.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Are you sure crack was due to the fault in the vacuum, or was it broken before that?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I think it was fine when we purchased, it broke after its's first run\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I am unhappy with the kind of support I am getting for a premium membership. This is a substandard assistance.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: It is very unfair and disappointing.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I have placed an order and never received it. But it shows as delivered.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: It is quite annoying when you send low quality products in general when I make a online delivery order\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I would certainly like to see an improvement in the next order\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Yes , There is also another problem with the order. I see that I have received two shampoos where as I added only one to my cart. \n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I would like to return it back and would want a refund on that as well.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: But on my screen it shows that you have placed 2 quantites of shampoo.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I ordered only one shampoo but got two I donât know why. I suppose there is some issue with the system and its not my mistake.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: I donât have any stores near by thatâs the reason I placed order for online delivery\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: it also disappoints me because of the kind of impression it leaves, being my first order.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Will that be of any help? Or will it also be a lost cause because I have to talk to him and explain him  the entire scenario. Which I feel is frustrating.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Alright go ahead connect me with him\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: Someone created an account using my gmail account but with a \".\" in it. This is still associate with my email address and is not my account. How can I delete this account?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: my name is not brittni.. my name is chris williams. my actual account is ctwilliXXXXX@gmail.com\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: this other account was created using ct.williXXXXX@gmail.com\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: i believe it is some sort of phishing attempt but I don't want this account associate with my email.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: hello?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: ok. my real account is ctwilliXXXXX@gmail.com NOT ct.williXXXXX@gmail.com - i had to password reset in order to get this account. Chris Williams\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: First = Chris Last = Williams\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: yah..im just here..Im so sorry for taking a long time to wait on this okay..?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: yes... ctwilliXXXXX@gmail.com is my account.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: i don't need you to reset my password\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: i need you to delete this \"ct.williXXXXX@gmail.com\" account because it is not mine.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: please don't change my password.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: maam?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: what is going on here?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: can you delete the account \"ct.williXXXXX@gmail.com\" or not?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: ok.\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: do you understand the problem i am having or is this a lost cause?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: can you please just let me know if this is a problem you can help resolve?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: delete my email?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: did you say delete my email?\n",
      "Model returned sentiment probabilities: [0]\n",
      "example input_str: hello?\n",
      "Model returned sentiment probabilities: [0]\n"
     ]
    },
    {
     "ename": "LayerError",
     "evalue": "Exception passing through layer Serial (in pure_fn):\n  layer created in file [...]/<ipython-input-19-118126b81272>, line 27\n  layer input shapes: ShapeDtype{shape:(1, 0), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 88, in forward\n    outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n\nLayerError: Exception passing through layer Embedding_437_256 (in pure_fn):\n  layer created in file [...]/<ipython-input-19-118126b81272>, line 8\n  layer input shapes: ShapeDtype{shape:(1, 0), dtype:float32}\n\n  File [...]/trax/layers/assert_shape.py, line 122, in forward_wrapper\n    y = forward(self, x, *args, **kwargs)\n\n  File [...]/trax/layers/core.py, line 181, in forward\n    embedded = jnp.take(self.weights, x, axis=0)\n\n  File [...]/_src/numpy/lax_numpy.py, line 4078, in take\n    slice_sizes=tuple(slice_sizes))\n\n  File [...]/_src/lax/lax.py, line 874, in gather\n    slice_sizes=canonicalize_shape(slice_sizes))\n\n  File [...]/site-packages/jax/core.py, line 282, in bind\n    out = top_trace.process_primitive(self, tracers, params)\n\n  File [...]/site-packages/jax/core.py, line 628, in process_primitive\n    return primitive.impl(*tracers, **params)\n\n  File [...]/jax/interpreters/xla.py, line 238, in apply_primitive\n    compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args), **params)\n\n  File [...]/jax/_src/util.py, line 198, in wrapper\n    return cached(bool(FLAGS.jax_enable_x64), *args, **kwargs)\n\n  File [...]/jax/_src/util.py, line 191, in cached\n    return f(*args, **kwargs)\n\n  File [...]/jax/interpreters/xla.py, line 263, in xla_primitive_callable\n    aval_out = prim.abstract_eval(*avals, **params)\n\n  File [...]/_src/lax/lax.py, line 1992, in standard_abstract_eval\n    shapes, dtypes = shape_rule(*args, **kwargs), dtype_rule(*args, **kwargs)\n\n  File [...]/_src/lax/lax.py, line 4114, in _gather_dtype_rule\n    raise ValueError(\"start_indices must have an integer type\")\n\nValueError: start_indices must have an integer type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLayerError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7ba45d408556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'example input_str: {sent}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model returned sentiment probabilities: {predictions.argmax(axis=1)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/trax/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, weights, state, rng)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m  \u001b[0;31m# Needed if the model wasn't fully initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpure_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/trax/layers/base.py\u001b[0m in \u001b[0;36mpure_fn\u001b[0;34m(self, x, weights, state, rng, use_cache)\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_short_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m       raise LayerError(name, 'pure_fn',\n\u001b[0;32m--> 549\u001b[0;31m                        self._caller, signature(x), trace) from None\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLayerError\u001b[0m: Exception passing through layer Serial (in pure_fn):\n  layer created in file [...]/<ipython-input-19-118126b81272>, line 27\n  layer input shapes: ShapeDtype{shape:(1, 0), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 88, in forward\n    outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n\nLayerError: Exception passing through layer Embedding_437_256 (in pure_fn):\n  layer created in file [...]/<ipython-input-19-118126b81272>, line 8\n  layer input shapes: ShapeDtype{shape:(1, 0), dtype:float32}\n\n  File [...]/trax/layers/assert_shape.py, line 122, in forward_wrapper\n    y = forward(self, x, *args, **kwargs)\n\n  File [...]/trax/layers/core.py, line 181, in forward\n    embedded = jnp.take(self.weights, x, axis=0)\n\n  File [...]/_src/numpy/lax_numpy.py, line 4078, in take\n    slice_sizes=tuple(slice_sizes))\n\n  File [...]/_src/lax/lax.py, line 874, in gather\n    slice_sizes=canonicalize_shape(slice_sizes))\n\n  File [...]/site-packages/jax/core.py, line 282, in bind\n    out = top_trace.process_primitive(self, tracers, params)\n\n  File [...]/site-packages/jax/core.py, line 628, in process_primitive\n    return primitive.impl(*tracers, **params)\n\n  File [...]/jax/interpreters/xla.py, line 238, in apply_primitive\n    compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args), **params)\n\n  File [...]/jax/_src/util.py, line 198, in wrapper\n    return cached(bool(FLAGS.jax_enable_x64), *args, **kwargs)\n\n  File [...]/jax/_src/util.py, line 191, in cached\n    return f(*args, **kwargs)\n\n  File [...]/jax/interpreters/xla.py, line 263, in xla_primitive_callable\n    aval_out = prim.abstract_eval(*avals, **params)\n\n  File [...]/_src/lax/lax.py, line 1992, in standard_abstract_eval\n    shapes, dtypes = shape_rule(*args, **kwargs), dtype_rule(*args, **kwargs)\n\n  File [...]/_src/lax/lax.py, line 4114, in _gather_dtype_rule\n    raise ValueError(\"start_indices must have an integer type\")\n\nValueError: start_indices must have an integer type"
     ]
    }
   ],
   "source": [
    "for sent in train_x:\n",
    "    inputs = np.array(sent_to_tensor(sent, vocab_dict=Vocab))\n",
    "    inputs = inputs[None, :]\n",
    "    predictions=model(inputs)\n",
    "    print(f'example input_str: {sent}')\n",
    "    print(f'Model returned sentiment probabilities: {predictions.argmax(axis=1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
